from collections import namedtuple
import hashlib
import itertools
import logging
import os
import platform
from random import Random
import subprocess
import sys
import traceback
import requests
import json
import datetime

from joblib import Parallel, delayed


def clone(repo, repodir):
    !git clone -q --depth 1 --single-branch  https://1:2@github.com/{repo} {repodir}
#     runcmd(
#         # f"git clone --depth 1 https://123:123@github.com/{repo}.git {repodir}",
#         # f"git clone --depth 1 https://www.github.com/{repo}.git {repodir}",
#         # f"git clone --depth 1 https://gitclone.com/github.com/{repo}.git {repodir}",
#         f"git clone --depth 1 --single-branch --filter=blob:none https://github.com/{repo} {repodir}; echo {repo} >> {args.done}",
#         check=True,
#     )


def runcmd(command, check=False, pout=False):
    try:
        ret = subprocess.run(
            command,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            encoding="utf-8",
            shell=True,
        )
        if check and ret.returncode:
            raise Exception(ret)
        if pout or check:
            print(ret)
        return ret.stdout.strip()
    except Exception as e:
        print(ret)
        if check:
            raise e


def filter(pyfile):
    try:
        if not pyfile.endswith(".py") or not os.path.isfile(pyfile):
            return

        size = os.path.getsize(pyfile)
        if not 0 < size < 1048576:
            return

        myhash = hashlib.md5()
        with open(pyfile, "rb") as f:
            for line in f:
                if len(line.decode("utf-8")) > 1000:
                    return
                myhash.update(line)
        md5 = myhash.hexdigest()
        balance_dir = md5[0 : args.balance]

        pyfile_new = f"{args.filtered}/{balance_dir}/{size}-{md5}.py"
        if os.path.exists(pyfile_new):
            return

        os.rename(pyfile, pyfile_new)

        logging.debug(f"{pyfile} -> {pyfile_new}")
    except Exception as e:
        logging.error(f"pyerr : {pyfile} -> {traceback.format_exc()}")


def findpy(base):
    for root, ds, fs in os.walk(base):
        for f in fs:
            yield os.path.join(root, f)


def remove(path):
    if platform.system() == "Windows":
        runcmd(f"powershell rm -Force -Recurse {path}")
    else:
        runcmd(f"rm -rf {path}")


def upload(index):
    print(f'upload piece: {index}')
    ballname = f'piece-{index}.tar.gz'
    !find {args.filtered}/ -type f > tmp
    !tar -zcf {ballname} --files-from=tmp --remove-files && curl -X POST -F 'file=@{ballname}' {args.remote} 
    # !cp {ballname} drive/MyDrive/


def download_repo(index, line):
    line = line.strip()
    repo = line.split(",")[0]
    file_name = repo.replace("/", "-")
    try:
        # 下载repo
        repodir = f"{args.source}/{file_name}"
        clone(repo, repodir)

        # 删除.git文件夹
        gitdir = f"{repodir}/.git"
        remove(gitdir)

        # 过滤py文件 > 重命名size-md5.py > 移到output-filter目录
        for pyfile in findpy(repodir):
            filter(pyfile)

        # 将repo目录置空
        !rm -rf {repodir}

        if index % 100 == 0:
            print(f"index:{index} repo:{repo} {datetime.datetime.now()}")
    except Exception:
        logging.error(f"repoerr : {line} -> {traceback.format_exc()}")


# clone repos to output, filter to output-filtered
if __name__ == "__main__":
    Args = namedtuple(
        "Args",
        [
            "repos",
            "source",
            "filtered",
            "log",
            "balance",
            "clean",
            "njobs",
            "done",
            "batch",
            "remote",
        ],
    )
    args = Args(
        "/content/drive/MyDrive/repos",
        "output-source",
        "output-filtered",
        "log",
        0,
        True,
        4,
        "/content/drive/MyDrive/repos-done",
        100000,
        "https://9e8d-221-12-13-243.jp.ngrok.io",
    )
    tmp = {"count": 0}
    if len(sys.argv) > 1:
        # args.repos = sys.argv[1]
        print(sys.argv)

    logging.basicConfig(level=logging.INFO)

    if not os.path.isdir(args.source):
        os.makedirs(args.source)
    if not os.path.isdir(args.filtered):
        os.makedirs(args.filtered)
        # os.makedirs('tmpdir')
    if args.balance > 0:
        for i in itertools.product("0123456789abcdef", repeat=args.balance):
            balance_dir = f'{args.filtered}/{"".join(i)}'
            if not os.path.isdir(balance_dir):
                os.makedirs(balance_dir)

    while True:
        res = requests.post(f'{args.remote}/repos/piece/generate')
        print(res)
        a = json.loads(res.text)
        piece_id = a['members'][0]
        repos = a['members'][1]
        print(f'get piece: {piece_id} counts: {len(repos)}')
        Parallel(n_jobs=args.njobs, prefer="threads")(
            delayed(download_repo)(index, line) for index, line in enumerate(repos)
        )
        upload(piece_id)
    print(123)